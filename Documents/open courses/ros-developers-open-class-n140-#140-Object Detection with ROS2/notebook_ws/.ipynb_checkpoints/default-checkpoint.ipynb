{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKVmOzupi70R"
   },
   "source": [
    "<img src=\"images/logos/The-Construct-logo-new.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS Developers Open Class n.140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Open-Class-140.jpeg\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Launch the Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the simulation, first we'll need to source our workspace:\n",
    "\n",
    "- Open a terminal window by clicking on the shell icon on the bottom left side of your screen:\n",
    "\n",
    "<img src=\"images/shell-superapp.png\" width=\"450\" />\n",
    "\n",
    "- Copy and paste the following terminal commands in your shell:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source simulation_ws/devel/setup.bash\n",
    "roslaunch ur_e_gazebo ur3e_start.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This sets up our environment and launches the simulation. Run the following command on a shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! You should be able to see the simulation and control everything as if it was the real robot if you go to the Gazebo button in the bottom left side of your screen:\n",
    "\n",
    "<img src=\"images/gazebo-icon.png\" width=\"100\" />\n",
    "\n",
    "\n",
    "**Wait around 30 seconds maximum** for the simulaion to start and you should see this simulation now:\n",
    "\n",
    "\n",
    "<img src=\"images/ur3e-sim.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKVmOzupi70R"
   },
   "source": [
    "<div class=\"jumbotron m-0\">\n",
    "    <hr />\n",
    "    <h1 class=\"text-center\">\n",
    "        <span class=\"text-primary\">\n",
    "            Object Detection with ROS2\n",
    "        </span>\n",
    "    </h1>\n",
    "    <hr />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2 class=\"text-center\">\n",
    "        <span class=\"text-primary\">1</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">What is Perception?</span>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In robotics, we understand **perception** as the way in which robots are capable of perceiving the world that surrounds them based on input sensory data. This perception of the environment is very helpful for robots in order to perform any required task.\n",
    "\n",
    "When working with manipulator robots, one of the main goals of reach is picking an object up from one position, and placing it in another one, which is commonly known as pick & place. Although this may sound like a very simple task, it is not. In fact, it's a very complex process because lots of variables need to be taken into account when picking up the object. For instance, how does the robot know where the object to pick is placed?\n",
    "\n",
    "Well, the goal of this Unit is to teach you how to answer to this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2 class=\"text-center\">\n",
    "        <span class=\"text-primary\">2</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">The simple_grasping package</span>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Open Class, we are going to be using the **simple_grasping** ROS2 package. This package was developed by Mike Ferguson, so a big shoutout to his amazing work. For this class, we have done some modifications to the original code in order to better adapt it to the material, but here you can check the original code: https://github.com/mikeferguson/simple_grasping/tree/ros2\n",
    "\n",
    "This package is very useful for manipulation since it will handle the detection of the object/s to pick and it can also generate the grasp poses for many types of objects. And it's quite simple, which helps in the process of learning. This package gets the position of the object to be picked from a 3D camera sensor (PointCloud), and generates the necessary grasping sequences in order to pick the object up. For this class, however, we will just focus on the Object Decection part and we will leave aside all the grasping part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the first thing we are going to do is get the code of the **simple_grasping** package. To do so, you can execute the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws/src\n",
    "git clone https://bitbucket.org/theconstructcore/perception_ros2.git\n",
    "cd ..\n",
    "source /opt/ros/foxy/setup.bash\n",
    "colcon build\n",
    "source install/setup.bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you **don't have ROS1 Noetic sourced** and you **properly source ROS2 Foxy** in the Shell where you compile the Perception packages. Otherwise, you might get errors derived from the mixing of ROS1 and ROS2 libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - End of Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this repository contains 4 packages:\n",
    "\n",
    "* **geometry2**: Packages which provide a Transform Library interface for ROS2.\n",
    "\n",
    "\n",
    "* **grasping_msgs**: Messages needed by the `simple_grasping` package.\n",
    "\n",
    "\n",
    "* **perception_pcl**: Packages which provide a PCL (Point Cloud Library) interface for ROS2.\n",
    "\n",
    "\n",
    "* **simple_grasping**: The `simple_grasping` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inside the **simple_grasping** package, you will see a folder named **src**. Here is where all the main programs of the package are located. Within this chapter, though, we are going to focus on 2 of them:\n",
    "\n",
    "* **basic_grasping_perception.cpp**: This script, as you can see, is written in C++. It provides an action server named `/find_objects`, which can be called in order to trigger the object detection pipeline.\n",
    "\n",
    "\n",
    "* **object_support_segmentation.cpp**: This script, as you can see, is written in C++. Its main functionality is to process the data received from the PointCloud 3D camera in order to detect any pickable objects in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2 class=\"text-center\">\n",
    "        <span class=\"text-primary\">3</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">Depth Camera Sensor</span>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following commands in order to spawn a pickable object into the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /opt/ros/noetic/setup.bash\n",
    "cd ~/catkin_ws/src\n",
    "rosrun gazebo_ros spawn_model -file grasp_box.urdf -urdf -x 0.5 -y 0.13 -z 0.1 -model grasp_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, you should have a grasping cube right in front of the UR3e arm, like in the image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/grasping_cube.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So, now we are actually ready to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by analyzing the data published by the Depth Camera. As you may imagine, this data is being published in ROS1. You can easily check the different topics published by the camera by running the commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rostopic list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    Expected Output\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "/wrist_rgbd/depth/camera_info\n",
    "/wrist_rgbd/depth/image_raw\n",
    "/wrist_rgbd/depth/points\n",
    "/wrist_rgbd/parameter_descriptions\n",
    "/wrist_rgbd/parameter_updates\n",
    "/wrist_rgbd/rgb/camera_info\n",
    "/wrist_rgbd/rgb/image_raw\n",
    "/wrist_rgbd/rgb/image_raw/compressed\n",
    "/wrist_rgbd/rgb/image_raw/compressed/parameter_descriptions\n",
    "/wrist_rgbd/rgb/image_raw/compressed/parameter_updates\n",
    "/wrist_rgbd/rgb/image_raw/compressedDepth\n",
    "/wrist_rgbd/rgb/image_raw/compressedDepth/parameter_descriptions\n",
    "/wrist_rgbd/rgb/image_raw/compressedDepth/parameter_updates\n",
    "/wrist_rgbd/rgb/image_raw/theora\n",
    "/wrist_rgbd/rgb/image_raw/theora/parameter_descriptions\n",
    "/wrist_rgbd/rgb/image_raw/theora/parameter_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are different topics being published by the camera. In this case, the topic that we are most interested in is the one named **/wrist_rgbd/depth/points**. Why? Well, this topic is the one that contains the Depth data (PointCloud). This PointCloud will be used by our Perception programs (**simple_grasping**) in order to detect the objects in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we already said before, this data is being published in ROS1, so... what should we do? Yes, you are right! We have to convert this data to ROS2. \n",
    "\n",
    "For this purpose we can make use of the **parameter_bridge** node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ~/catkin_ws/devel/setup.bash\n",
    "roslaunch load_params load_params.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run the parameter_bridge node:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /home/simulations/ros2_sims_ws/install/setup.bash\n",
    "ros2 run ros1_bridge parameter_bridge __name:=parameter_bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about the ROS1 Bridge, have a look at our <a href=\"https://app.theconstructsim.com/#/Course/61\" target=\"_blank\">ROS2 Basics C++ course</a>.\n",
    "\n",
    "You can also review this other <a href=\"https://app.theconstructsim.com/#/LiveClass/a594c098-c957-44aa-9333-40fe61c03331\" target=\"_blank\">Open Class</a> where we explain much more about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - End of Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally verify that the topics are being properly bridged by visualizing the PointCloud data in Rviz2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /opt/ros/foxy/setup.bash\n",
    "rviz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/depth_rviz2.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2 class=\"text-center\">\n",
    "        <span class=\"text-primary\">4</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">Running the Object Detection nodes</span>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command to start the Object Detection Action Server is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 run simple_grasping basic_grasping_perception_node --ros-args -p debug_topics:=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, what we are doing here is to start a ROS2 node named `basic_grasping_perception_node`, which is the one contained in the **basic_grasping_perception.cpp** script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check basic grasping perception topics are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When the program is running, a new action server will be created. You can check it by using **_ros2 action list_**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 action list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see an Action Server named **find_objects**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    Expected Output\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/find_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling this Action Server, we will ask the robot to find any object close to him that is graspable. We will do this in just a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if you run a `ros2 topic list` command, you will see 2 extra topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/object_cloud\n",
    "/support_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 2 topics will allow you to visualize, using Rviz2, what the robot is detecting. The **/object_cloud** will show you the objects detected, and the **/support_cloud** will show you the surface where these objects are placed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Call the action server to ACTIVATE the object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do will be to CALL this Action Server, in order to see if it detects any object. For that, you'll need to run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 action send_goal /find_objects grasping_msgs/action/FindGraspableObjects \"{plan_grasps: false}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter **plan_grasps** indicates whether we want to calculate the possible grasps or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please bear in mind that the **`/find_objects`** action server might take some time to respond (not for RViz2 visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - End of Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By sending a goal to the **/find_objects** Action Server, you are triggering the system to look for objects around the scene. After some seconds, you will get a result message similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    Expected Output\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Waiting for an action server to become available...\n",
    "Sending goal:\n",
    "     plan_grasps: false\n",
    "\n",
    "Goal accepted with ID: 8700ae9645314b0d98018b446a2818f8\n",
    "\n",
    "Result:\n",
    "    objects:\n",
    "- object:\n",
    "    header:\n",
    "      stamp:\n",
    "        sec: 1634920618\n",
    "        nanosec: 76980389\n",
    "      frame_id: base_link\n",
    "    name: ''\n",
    "    support_surface: surface0\n",
    "    properties: []\n",
    "    point_cluster:\n",
    "      header:\n",
    "        stamp:\n",
    "          sec: 0\n",
    "          nanosec: 0\n",
    "        frame_id: ''\n",
    "      height: 1\n",
    "      width: 1760\n",
    "      fields:\n",
    "      - name: x\n",
    "        offset: 0\n",
    "        datatype: 7\n",
    "        count: 1\n",
    "      - name: y\n",
    "        offset: 4\n",
    "        datatype: 7\n",
    "        count: 1\n",
    "      - name: z\n",
    "        offset: 8\n",
    "        datatype: 7\n",
    "        count: 1\n",
    "      - name: rgb\n",
    "        offset: 16\n",
    "        datatype: 7\n",
    "        count: 1\n",
    "      is_bigendian: false\n",
    "      point_step: 32\n",
    "      row_step: 56320\n",
    "      data:\n",
    "      - 103\n",
    "      - 28\n",
    "      - 208\n",
    "    \n",
    "...\n",
    "\n",
    "      - 128\n",
    "      - 63\n",
    "      is_dense: true\n",
    "  primitives:\n",
    "  - type: 1\n",
    "    dimensions:\n",
    "    - 9.568283081054688\n",
    "    - 4.955076992511749\n",
    "    - 0.007858745753765106\n",
    "  primitive_poses:\n",
    "  - position:\n",
    "      x: 0.48848390579223633\n",
    "      y: -2.0752249658107758\n",
    "      z: -0.09606975689530373\n",
    "    orientation:\n",
    "      x: 0.0\n",
    "      y: 0.0\n",
    "      z: 0.0\n",
    "      w: 1.0\n",
    "  meshes: []\n",
    "  mesh_poses: []\n",
    "  surface:\n",
    "    coef:\n",
    "    - -2.9003527743043378e-05\n",
    "    - 2.6923982659354806e-05\n",
    "    - 1.0\n",
    "    - 0.10009085386991501\n",
    "\n",
    "Goal finished with status: SUCCEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the result message returned by the Action Server is HUGE. Let's try to understand it a little bit better. We know that the Action Server uses the interface `grasping_msgs/action/FindGraspableObjects`, so let's get some more data about it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 interface show grasping_msgs/action/FindGraspableObjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    Expected Output\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# This action is called for integrated object detection and\n",
    "#  grasp planning, such as in base_grasping_perception\n",
    "\n",
    "# Set to false to disable grasp planning, returning only the objects found\n",
    "bool plan_grasps\n",
    "---\n",
    "# Graspable objects found\n",
    "GraspableObject[] objects\n",
    "\n",
    "# Additional, non-graspable objects which may be support surfaces\n",
    "Object[] support_surfaces\n",
    "---\n",
    "# Publish objects as they are detected and grasp planned\n",
    "GraspableObject object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the result message contains 2 arrays, one for the objects detected, `GraspableObject[] objects`, and another one for the surfaces, `Object[] support_surfaces`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, the result data is not easy to understand as it is. What if we ask RViz2 for some help here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the detections in Rviz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open RViz2 if you don't have it already running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rviz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rviz2_raw.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add two additional PointCloud displays in order to visualize the following 2 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/object_cloud\n",
    "/support_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set the **Reliability Policy** of the Topics to **Best Effort**. Otherwise, you won't be able to visualize the detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/best_effort.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about Quality of Service (QoS) settings in ROS2, have a look at this other <a href=\"https://app.theconstructsim.com/#/LiveClass/c1bd5d4b-487b-4f20-a728-8997e1b5e483\" target=\"_blank\">Open Class</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-info text-center\">\n",
    "    - End of Notes -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to send a goal again to the Action Server:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in Shell\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 action send_goal /find_objects grasping_msgs/action/FindGraspableObjects \"{plan_grasps: false}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now be able to visualize the objects detected, and the surface where the object is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rviz2_detection.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now save this **RViz2 configuration file** with the name **perception.rviz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep learning and practicing ROS2 with our upcoming WORKSHOPS\n",
    "\n",
    "**Stay tuned to the [UPCOMING WORKSHOPS](https://app.theconstructsim.com/#/LiveClasses)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROS2 Industrial Workshop](images/upcoming-workshops.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you liked this class, please support us!\n",
    "# Really... we need your support!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can you support us?\n",
    "## 1. Subscribe to our ROS online academy and become a ROS Developer\n",
    "\n",
    "Go to our online academy. There is no faster way and funnier to learn ROS because we use the same\n",
    "method we did here.\n",
    "\n",
    "**We call it the 30/70 method**\n",
    "\n",
    "\n",
    "* **30% of the time learning theory**\n",
    "* **70% of the time practicing with simulated robots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/courses_dashboard_new.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check it out at http://robotignite.academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Buy a ROS Developer T-shirt or one of our mugs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/mugs.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/T-shirts.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can buy them at our Teespring area (https://teespring.com/stores/ros-developers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Give us a like in Youtube and subscribe to the channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Go to our Youtube Channel (https://www.youtube.com/channel/UCt6Lag-vv25fTX3e11mVY1Q) and subscribe (it is free!!!)**\n",
    "* **Give us a like to this video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEEP PUSHING YOUR ROS LEARNING WITH PATIENCE AND GOOD HUMOUR!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the future, Become a ROS DEVELOPER!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-gXVv0x7JCVH",
    "DWJVcmhj0PAI",
    "cUYXevdcdmvz",
    "tAtKbJLddtts",
    "dHky_ri5dtqv",
    "OOVbIGbBfABL",
    "mAV21bUTlsdK"
   ],
   "name": "unit2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
